어떻게 운영체제라는 방대한 내용을 정리할 수 있을까 고민이 되었는데,

스터디가 면접 준비, 면접 스터디인 만큼 면접에서 나오는 질문들 위주로 정리를 해보려고 합니다.

### OS의 역할과 시스템의 기초

가장 먼저 운영체제가 무엇이고, 사용자와 하드웨어 사이에서 어떻게 중재하는지 설명합니다.

- **핵심 키워드:** 커널, 인터럽트, 시스템 콜
- **질문들:**
  - 커널은 무엇인가요? (OS의 심장)
  - 프로그램과 프로세스의 차이는 무엇인가요? (정적인 코드 vs 실행 중인 주체)
  - 시스템 콜이란? 왜 필요한가요? (사용자 모드 vs 커널 모드 접근 제어)
  - 인터럽트에 대해 설명하고, 발생 시 수행 과정을 간략히 말해주세요.

운영체제가 부팅된 후, 메모리에 상주하며 시스템의 모든 자원을 통제하는 핵심부를 커널이라고 합니다. 커널은 보안을 위해 사용자가 하드웨어에 직접 접근하는 것을 막고, 두 가지 모드로 시스템을 운영합니다.

**1) 이중 모드 (Dual Mode)와 시스템 콜**

컴퓨터는 안정성을 위해 사용자 모드(User Mode)와 커널 모드(Kernel Mode)로 나뉩니다.

- 사용자 모드: 우리가 실행하는 응용 프로그램이 동작하는 영역입니다. 하드웨어 접근 권한이 없습니다.
- 커널 모드: 모든 시스템 자원에 접근할 수 있는 특권 모드입니다.
- 시스템 콜은 사용자 모드의 프로그램이 커널의 기능을 빌려 쓰기 위해 호출하는 인터페이스(API)입니다. 파일을 읽거나(read), 화면에 출력하거나(write), 프로세스를 생성(fork)하는 행위는 모두 커널 모드 권한이 필요하므로 시스템 콜을 통해 수행됩니다.

**2) 인터럽트 (Interrupt)**

CPU는 한 번에 하나의 일만 처리할 수 있습니다. 그렇다면 마우스 움직임이나 키보드 입력은 어떻게 즉각 반응할까요? 바로 인터럽트 덕분입니다. CPU가 프로그램을 실행하고 있을 때, 입출력 장치나 예외 상황이 발생하여 처리가 필요하다는 신호를 보내는 메커니즘입니다.

- 처리 과정:
  1. 인터럽트 발생
  2. 현재 실행 중인 프로세스의 상태(Context)를 저장
  3. 인터럽트 처리 루틴(ISR) 실행
  4. 저장했던 프로세스 상태 복구 및 재개

### 실행의 주체: 프로세스와 스레드 (Process & Thread)

프로그램이 실행될 때 메모리에 어떻게 적재되고, CPU는 이것들을 어떻게 다루는지 설명합니다.

- **핵심 키워드:** PCB, 컨텍스트 스위칭, 멀티 태스킹
- **질문들:**
  - 프로세스와 스레드의 차이는? / 멀티프로세스와 멀티스레드의 차이는?
  - PCB(Process Control Block)가 무엇인지 설명해주세요.
  - 프로세스의 상태 변화(State Transition)에 대해 설명해주세요. (생성-준비-실행-대기-종료)
  - 컨텍스트 스위칭(Context Switching)이란?
  - 스레드마다 독립적으로 스택 영역을 갖는 이유는?
  - 좀비 프로세스, 고아 프로세스란?
  - 크롬 브라우저의 탭은 프로세스일까요, 스레드일까요?
  - 멀티 프로세스 환경에서 데이터는 어떻게 주고받나요? (IPC: 공유메모리 vs 메시지 전달 장단점)

이 파트의 핵심은 메모리 공유 여부입니다.

**1) 프로세스 (Process)**
디스크에 있는 프로그램(Code)이 메모리에 적재되어 실행 중인 상태입니다.

- 메모리 구조: 프로세스는 OS로부터 독립적인 메모리 공간을 할당받습니다.
  - Code: 실행할 코드가 저장되는 영역
  - Data: 전역 변수, 정적 변수
  - Heap: 사용자가 동적으로 할당하는 영역 (런타임 결정)
  - Stack: 지역 변수, 매개 변수, 함수 호출 흐름 (컴파일 타임 결정)

**2) 스레드 (Thread)**
프로세스 내에서 실행되는 실행 흐름의 단위입니다.

- 특징:
  - 프로세스의 자원(Code, Data, Heap)을 다른 스레드와 공유합니다.
  - Stack 영역과 PC(레지스터)는 스레드별로 독립적으로 가집니다.
  - Why Stack? 스택은 함수 호출과 지역 변수를 관리합니다. 독립적인 실행 흐름을 가지려면 독립적인 함수 호출이 가능해야 하므로 스택은 따로 가져야 합니다.

**3) 멀티 프로세스 vs 멀티 스레드**

| 구분 | 멀티 프로세스 (Multi-Process)                        | 멀티 스레드 (Multi-Thread)                         |
| ---- | ---------------------------------------------------- | -------------------------------------------------- |
| 개념 | 하나의 프로그램을 여러 프로세스로 병렬 처리          | 하나의 프로세스 안에서 여러 흐름을 병렬 처리       |
| 장점 | 안정성 (하나가 죽어도 다른 것에 영향 X)              | 효율성 (자원 공유, 생성 비용 적음, 통신 간단)      |
| 단점 | 오버헤드 큼 (Context Switching 비용), 통신 복잡(IPC) | 동기화 문제 발생, 하나가 죽으면 전체 프로세스 종료 |
| 통신 | IPC 필요 (공유 메모리, 메시지 전달, 소켓 등)         | 공유 변수 이용 (별도 통신 불필요)                  |

**4) PCB와 컨텍스트 스위칭**

- PCB (Process Control Block): 운영체제가 프로세스를 관리하기 위해 만드는 기록표입니다. (PID, 상태, PC값, 레지스터 값 등 저장)
- 컨텍스트 스위칭 (Context Switching): CPU가 현재 프로세스를 중단하고 다른 프로세스로 넘어갈 때, 이전 프로세스의 상태(PCB)를 저장하고 새 프로세스의 상태를 불러오는 작업입니다. 이 과정은 오버헤드입니다.

### CPU 스케줄링 (CPU Scheduling)

여러 프로세스가 실행될 때, 누구에게 CPU를 줄지 결정하는 방법입니다.

- **핵심 키워드:** 선점/비선점, 기아 상태, 효율성
- **질문들:**
  - 선점형 vs 비선점형 스케줄링 차이
  - CPU 스케줄링 알고리즘 종류와 특징 (RR, FCFS 등)
  - Round Robin에서 Time Slice 크기에 따른 Trade-off는?
  - 콘보이 현상(Convoy Effect)과 기아 상태(Starvation)란?

준비 상태(Ready)에 있는 여러 프로세스 중 누구에게 CPU를 줄 것인가를 결정하는 과정입니다.

**1) 선점형 vs 비선점형**

- 선점형 (Preemptive): OS가 강제로 CPU를 빼앗을 수 있습니다. (예: Round Robin). 응답성이 중요할 때 쓰입니다.
- 비선점형 (Non-preemptive): 프로세스가 스스로 끝내거나 반납할 때까지 기다려줍니다. (예: FCFS). 공정하지만 응답성이 떨어집니다.

**2) 주요 알고리즘과 Trade-off**

- FCFS (First Come First Served): 먼저 온 거 먼저 처리.
  - 콘보이 현상 (Convoy Effect): 실행 시간이 긴 프로세스가 먼저 도착하면 뒤의 짧은 프로세스들이 하염없이 기다리는 비효율 발생.
- RR (Round Robin): 정해진 시간(Time Slice)만큼만 쓰고 돌아가며 실행.
  - Time Slice Trade-off: 시간이 너무 크면 FCFS와 같아지고, 너무 작으면 컨텍스트 스위칭 비용이 너무 커져서 오버헤드가 발생합니다.

**3) 기아 상태 (Starvation)**

우선순위 스케줄링에서 우선순위가 낮은 프로세스가 계속해서 CPU를 할당받지 못하고 무한히 대기하는 현상입니다.

해결책: 오래 기다리면 우선순위를 높여주는 Aging 기법

### 동시성 제어와 동기화 (Concurrency & Synchronization)

여러 스레드가 동시에 자원에 접근할 때 발생하는 문제와 해결책입니다.

- **핵심 키워드:** 데드락, 뮤텍스/세마포어, 경쟁 상태(Race Condition)
- **질문들:**
  - 동기와 비동기, 동시성과 병렬성의 차이는?
  - 임계 영역(Critical Section) 문제 해결을 위한 3가지 조건
  - 프로세스 동기화란 무엇이며 방법에는 무엇이 있나요?
  - 뮤텍스와 세마포어의 차이 / 이진 세마포어란?
  - **[**데드락(Deadlock) 발생 조건 4가지와 해결 방법 (은행원 알고리즘 등)
  - Thread-safe하다는 의미는? / 여러 스레드에서 공유 자원 접근 시 주의점
  - `synchronized` 키워드(메소드 vs 블록) 차이 / 싱글톤의 동시성 문제

여러 스레드(또는 프로세스)가 동시에 실행될 때, 공유 자원에 접근하면서 데이터가 꼬이는 문제를 막는 것입니다.

**1) 경쟁 상태와 임계 영역**

- 경쟁 상태(Race Condition): 여러 스레드가 동시에 공유 데이터에 접근하고 수정하려 할 때, 타이밍에 따라 결과가 달라지는 상황입니다.
- 임계 영역(Critical Section): 공유 데이터에 접근하는 코드 영역입니다. 이 영역은 한 번에 하나의 스레드만 들어가야 합니다.
- 임계 영역 문제 해결을 위한 3가지 조건:
  1. 상호 배제 (Mutual Exclusion): 누군가 들어가 있으면 다른 건은 못 들어감.
  2. 진행 (Progress): 아무도 없으면 들어갈 수 있어야 함. (무한 대기 X)
  3. 한정 대기 (Bounded Waiting): 기다리면 언젠가는 들어갈 수 있어야 함. (기아 상태 방지)

**2) 해결책: 뮤텍스 vs 세마포어**

둘 다 동기화 도구지만 작동 방식이 다릅니다.

- 뮤텍스 (Mutex): Locking 메커니즘입니다. 화장실 열쇠가 하나뿐인 상황과 같습니다. 열쇠를 가진 스레드만 들어갈 수 있고, 나갈 때 열쇠를 반납합니다. (소유권 O)
- 세마포어 (Semaphore): Signaling 메커니즘입니다. 빈 칸의 개수를 나타내는 변수(카운터)를 사용합니다.
  - 이진 세마포어: 0과 1만 가짐. (뮤텍스와 유사하게 동작)
  - 카운팅 세마포어: 자원이 여러 개일 때 사용.
- 결정적 차이: 뮤텍스는 락을 건 스레드만 락을 풀 수 있지만, 세마포어는 다른 스레드가 신호(Signal)를 보내 락을 해제할 수도 있습니다.

**3) 데드락 (Deadlock, 교착 상태)**

두 개 이상의 프로세스가 서로 상대방의 자원을 기다리며 무한히 멈춰있는 상태입니다.

- **발생 조건 4가지 (모두 충족해야 발생):**
  1. 상호 배제: 자원은 한 번에 하나만 사용 가능.
  2. 점유 대기: 자원을 잡은 상태에서 다른 자원 기다림.
  3. 비선점: 남의 자원을 뺏을 수 없음.
  4. 순환 대기: 꼬리에 꼬리를 물고 기다림. (원형)
- **해결 방법:**
  - 예방: 4가지 조건 중 하나를 무력화함. (비효율적)
  - 회피: 은행원 알고리즘(Banker's Algorithm) 사용. 시스템이 안전 상태일 때만 자원을 할당해 줌.
  - 탐지 및 회복: 데드락이 발생하면 프로세스를 하나씩 죽이거나 롤백.

**4) Java에서의 동시성 (Thread-safe)**

- Thread-safe: 여러 스레드가 동시에 접근해도 프로그램 실행에 문제가 없는 상태입니다.
- synchronized 키워드:
  - 메소드: 메소드 전체에 락을 걺. 인스턴스 전체가 잠기므로 성능 저하 우려.
  - 블록: 필요한 부분만 락을 걺. 범위를 줄여 효율적.
- 싱글톤의 동시성 문제: 멀티 스레드 환경에서 `if (instance == null)` 체크 시 동시에 진입하면 객체가 2개 생성될 수 있습니다. (해결: Double-Checked Locking 등 사용)

### 메모리 관리 (Memory Management)

한정된 메모리(RAM)를 어떻게 쪼개서 쓰고, 부족할 때 어떻게 가상화하는지 설명합니다.

- **핵심 키워드:** 가상 메모리, 페이징, 단편화
- **질문들:**
  - 메모리 구조(Code, Data, Heap, Stack) 및 특성
  - MMU의 역할은?
  - 내부 단편화 vs 외부 단편화 차이와 문제점 (외부 조각 문제)
  - **[핵심]** 페이징과 세그먼테이션의 차이
  - 가상 메모리의 장점과 요구 페이징(Demand Paging)이란?
  - 스레싱(Thrashing)이란?
  - 캐시 메모리를 사용하는 이유와 지역성(Locality)
  - **[이슈]** Stack Overflow vs Heap Overflow / 힙 영역 메모리 누수 예방 / 최악 적합(Worst-fit)을 쓰는 이유

CPU는 메모리에 있는 것만 실행할 수 있는데, RAM 용량은 한정적입니다. 이를 극복하기 위한 기술들입니다.

**1) 메모리 단편화 (Fragmentation)**

메모리에 빈 공간이 있어도, 조각조각 나뉘어 있어서 큰 프로그램을 못 넣는 문제입니다.

- 외부 단편화 (External): 메모리 공간의 크기는 충분한데, 연속된 공간이 없어서 할당 못 함. (가변 분할 방식에서 주로 발생)
- 내부 단편화 (Internal): 할당해 준 공간이 실제 필요한 양보다 커서 내부에 낭비되는 공간이 생김. (고정 분할 방식에서 주로 발생)

**2) 페이징(Paging) vs 세그먼테이션(Segmentation)**

메모리를 쪼개서 관리하는 두 가지 핵심 기법입니다.

| 구분 | 페이징 (Paging)                             | 세그먼테이션 (Segmentation)             |
| ---- | ------------------------------------------- | --------------------------------------- |
| 단위 | 고정 크기 (Page)                            | 가변 크기 (Logical unit: 함수, 배열 등) |
| 특징 | 물리 메모리를 Frame이라는 같은 크기로 나눔  | 논리적 의미 단위로 나눔                 |
| 장점 | 외부 단편화 해결 (빈 곳 아무데나 넣으면 됨) | 논리적 단위라 보호/공유가 쉬움          |
| 단점 | 내부 단편화 발생 (마지막 페이지 남는 공간)  | 외부 단편화 발생 (크기가 들쭉날쭉함)    |

- MMU (Memory Management Unit): CPU가 요청하는 가상 주소를 물리 주소로 아주 빠르게 변환해 주는 하드웨어 장치입니다.

**3) 가상 메모리 (Virtual Memory)**

실제 물리 메모리(RAM)보다 큰 프로그램을 실행할 수 있게 해주는 기술입니다.

- 원리: 프로그램 전체를 메모리에 올리지 않고, 당장 필요한 부분만 올리고(Demand Paging), 나머지는 디스크(Swap 영역)에 둡니다.
- 스레싱 (Thrashing): 메모리가 너무 부족해서 프로세스 실행보다 페이지 교체(Swap In/Out)에 시간을 다 쓰는 현상. CPU 이용률이 급격히 떨어짐.

**4) 캐시 메모리와 지역성 (Locality)**

- 사용 이유: CPU 속도와 메모리 속도 차이를 줄이기 위해.
- 지역성의 원리:
  - 시간 지역성: 한 번 쓴 데이터는 또 쓸 확률이 높다. (예: 반복문 변수)
  - 공간 지역성: 특정 데이터 주변을 쓸 확률이 높다. (예: 배열)

**5) 힙(Heap) vs 스택(Stack) 이슈**

- Stack Overflow: 재귀 호출이 너무 깊어지거나 지역 변수가 너무 많아 스택 영역을 초과할 때.
- Heap Overflow: `new` 등으로 동적 할당을 계속하고 해제(GC)하지 않아 힙 영역을 초과할 때.
- 메모리 누수(Leak): 더 이상 안 쓰는 객체가 힙에 남아있는 것. (Java는 GC가 해주지만, 참조가 남아있으면 GC 대상이 안 됨)
