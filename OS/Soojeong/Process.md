### 왜 운영체제는 프로세스를 관리할까

운영체제의 가장 중요한 역할은 하드웨어 자원을 효율적이고 안전하게 관리하는 것이다.

그중에서도 CPU와 메모리는 모든 프로그램이 반드시 사용하는 핵심 자원이다.

하지만 CPU와 메모리는 단순히 “프로그램”을 대상으로 관리할 수 없다.

디스크에 저장된 프로그램은 그저 코드와 데이터가 들어 있는 파일일 뿐,

스스로 실행되거나 자원을 요구하지 않는다.

운영체제는 **실제로 실행되는 대상**,

즉 CPU 시간을 할당받아 동작하는 존재를 관리해야 했고,

그 결과 등장한 개념이 **프로세스(Process)**다.

---

### 프로세스의 개념과 본질

- 프로그램과 프로세스는 물리적으로 다르다.
- 프로세스는 실행 중인 존재다.
- 운영체제는 프로세스 단위로 자원을 관리한다.

프로그램은 **정적(Passive)**인 존재다.

디스크에 저장되어 있으며, 누군가 실행시키기 전까지는 아무 일도 하지 않는다.

반면 프로세스는 **동적(Active)**인 존재다.

프로그램이 메모리에 적재되고, CPU의 실행 흐름을 부여받아 실제로 명령어를 수행하는 순간 프로세스가 된다.

따라서 하나의 프로그램을 여러 번 실행하면, 운영체제는 **서로 독립적인 여러 개의 프로세스**를 생성한다.

이 독립성 덕분에 한 프로세스가 오류로 종료되더라도 다른 프로세스에는 영향을 주지 않는다.

운영체제가 프로그램이 아니라 **프로세스 단위로 관리하는 이유**가 바로 여기에 있다.

---

### 프로세스의 구성 요소

- 프로세스는 메모리 공간을 가진다.
- 실행 상태를 저장해야 한다.
- 운영체제는 PCB로 프로세스를 관리한다.

1. 프로세스 주소 공간

   프로세스가 메모리에 올라가면, 운영체제는 해당 프로세스에게 독립적인 주소 공간을 제공한다.

   이 주소 공간은 일반적으로 다음 네 영역으로 구성된다.

   - **Code 영역**
     실행할 기계어 명령어가 저장된다.
     보통 읽기 전용이며, 동일한 프로그램을 실행하는 여러 프로세스가 코드 자체는 공유할 수 있다.
   - **Data 영역**
     전역 변수, 정적 변수가 저장된다.
     프로그램 시작 시 크기가 결정된다.
   - **Heap 영역**
     실행 중 동적으로 할당되는 메모리 공간이다.
     `malloc`, `new` 같은 동적 할당이 여기서 이루어진다.
   - **Stack 영역**
     함수 호출과 관련된 정보가 저장된다.
     지역 변수, 매개변수, 반환 주소 등이 포함되며 함수 호출과 함께 자동으로 증가·감소한다.

   이 구조의 핵심은 **프로세스마다 이 주소 공간이 완전히 분리되어 있다는 점**이다.

   이로 인해 프로세스 간 메모리 침범이 원천적으로 차단된다.

1. 사용자 영역과 커널 영역

   프로세스는 항상 마음대로 시스템 자원에 접근할 수 없다.

   운영체제는 안정성을 위해 실행 모드를 나눈다.

   - **User Mode(사용자 영역)**
     - 일반 애플리케이션 코드가 실행되는 영역
     - 제한된 명령만 수행 가능
   - **Kernel Mode(커널 영역)**
     - 운영체제 핵심 코드가 실행되는 영역
     - 하드웨어 및 자원 직접 제어 가능

   프로세스가 파일 입출력, 메모리 할당 같은 작업을 요청하면 **시스템 콜(System Call)** 을 통해 커널 영역으로 진입한다.

   이 구조 덕분에, 프로세스는 다른 프로세스나 하드웨어를 직접 망가뜨릴 수 없다.

1. 프로세스 문맥(Process Context)

   프로세스는 실행 도중 언제든 중단될 수 있다.

   타임 슬라이스 만료, I/O 요청, 인터럽트 등 그 이유는 다양하다.

   그럼에도 다시 정확히 이어서 실행되려면, **중단된 시점의 실행 상태를 저장**해야 한다.

   이 저장된 실행 상태를 **프로세스 문맥**이라고 한다.

   문맥에는 다음 정보가 포함된다.

   - Program Counter (다음 실행할 명령어 주소)
   - CPU 레지스터 값
   - 실행 상태 및 플래그 정보

   이 문맥이 없다면, 프로세스는 중단 이후 처음부터 다시 실행할 수밖에 없다.

1. PCB(Process Control Block)

   운영체제는 프로세스를 직접 관리하지 않는다.

   대신 각 프로세스마다 **PCB(Process Control Block)**를 만들어 관리한다.

   PCB는 프로세스의 모든 관리 정보를 담고 있는 **커널 자료구조**다.

   PCB에는 다음 정보들이 저장된다.

   - 프로세스 ID(PID)
   - 현재 상태(New, Ready, Running 등)
   - Program Counter
   - CPU 레지스터 값
   - 메모리 관리 정보
   - 스케줄링 정보

   운영체제는 이 PCB들을 **Linked List나 Queue 형태로 관리**하며, Ready Queue, Waiting Queue 등에 배치한다.

   즉, CPU를 어떤 프로세스에게 할당한다는 것은 **PCB를 기준으로 실행 대상을 선택하는 것**이다.

---

### 프로세스의 생명주기

- 프로세스는 여러 상태를 오간다.
- 상태 전이는 스케줄링의 기초다.
- Ready와 Waiting은 명확히 다르다.

프로세스는 생성부터 종료까지 다음과 같은 상태를 가진다.

- **New**: 프로세스가 생성 중인 상태
- **Ready**: 실행 준비 완료, CPU 할당 대기
- **Running**: CPU를 할당받아 실행 중
- **Waiting(Blocked)**: I/O 등 이벤트 대기
- **Terminated**: 실행 종료

여기서 가장 중요한 구분은 **Ready와 Waiting**이다.

- Ready 상태의 프로세스는
  CPU만 주어지면 즉시 실행 가능하다.
- Waiting 상태의 프로세스는
  이벤트가 끝나기 전까지 CPU를 줘도 실행할 수 없다.

이 차이는 스케줄링 판단의 핵심 기준이 된다.

---

### 프로세스 생성과 종료

- fork와 exec는 서로 다른 역할을 가진다.
- 프로세스는 부모-자식 관계를 형성한다.
- 종료 처리가 잘못되면 시스템 자원이 낭비된다.

유닉스 계열 운영체제에서 프로세스 생성은 `fork()` 시스템 콜로 이루어진다.

`fork()`는 현재 프로세스를 복제해 자식 프로세스를 만든다.

이때 실제 메모리를 바로 복사하지 않고 **Copy-on-Write** 기법을 사용해 효율을 높인다.

자식 프로세스는 이후 `exec()`를 호출해 자신의 메모리 공간을 새로운 프로그램으로 덮어쓴다.

프로세스가 종료되면 `exit()`가 호출되고,

부모가 `wait()`로 종료 상태를 수거하지 않으면 **좀비 프로세스**가 발생한다.

---

### 컨텍스트 스위칭과 CPU 가상화

- CPU는 하나뿐이다.
- 실행 중인 프로세스는 계속 바뀐다.
- 컨텍스트 스위칭에는 비용이 든다.

CPU는 한 번에 하나의 프로세스만 실행할 수 있다.

그럼에도 여러 프로세스가 동시에 실행되는 것처럼 보이는 이유는 **컨텍스트 스위칭** 때문이다.

컨텍스트 스위칭은

1. 현재 프로세스의 문맥을 PCB에 저장하고
2. 다음 프로세스의 문맥을 PCB에서 복원하는 과정

이다.

이 과정에는 비용이 따른다.

- 레지스터 저장/복원
- 캐시 오염
- TLB flush

그래서 운영체제는 컨텍스트 스위칭 횟수를 최소화하면서 응답성을 유지해야 한다.

---

### 프로세스 스케줄링

- Ready 상태 프로세스 중 실행 대상을 선택한다
- CPU 가상화의 핵심 메커니즘이다
- 공정성, 응답성, 처리량 사이의 트레이드오프 문제다

프로세스 스케줄링은

**여러 Ready 상태의 프로세스 중 어떤 프로세스에게 CPU를 할당할지 결정하는 과정**이다.

CPU는 한 번에 하나의 프로세스만 실행할 수 있기 때문에,

스케줄링 정책은 시스템 전체 성능과 사용자 체감 품질에 직접적인 영향을 미친다.

운영체제는 상황에 따라 서로 다른 목표를 가진 스케줄링 전략을 사용한다.

- 대화형 시스템 → **응답성**
- 배치 처리 시스템 → **처리량**
- 실시간 시스템 → **마감 시간 보장**

이 때문에 **완벽한 스케줄링 알고리즘은 존재하지 않는다**.

---

### 스케줄러의 종류와 역할

운영체제는 하나의 스케줄러만으로 CPU를 관리하지 않는다.

역할에 따라 다음 세 가지 스케줄러가 존재한다.

- **장기 스케줄러(Long-term Scheduler)**
  - 어떤 작업을 프로세스로 메모리에 올릴지 결정
  - 시스템에 동시에 존재하는 프로세스 수를 조절
  - 현대 시분할 OS에서는 거의 사용되지 않음
- **중기 스케줄러(Medium-term Scheduler)**
  - 메모리 부족 시 프로세스를 Swap-out / Swap-in
  - 멀티프로그래밍 정도 조절
  - Ready ↔ Suspended 상태 관리
- **단기 스케줄러(Short-term Scheduler)**
  - Ready Queue 중 어떤 프로세스에 CPU를 줄지 결정
  - 가장 자주 실행되며 성능에 가장 큰 영향
  - 우리가 흔히 말하는 “CPU 스케줄링”의 주체

---

### 선점형과 비선점형 스케줄링

스케줄링 알고리즘은 CPU를 **강제로 빼앗을 수 있는지**에 따라 나뉜다.

- **비선점형(Non-preemptive)**
  - 프로세스가 CPU를 자발적으로 반납할 때까지 실행
  - 구현 단순, 응답성 낮음
  - 예: FCFS, 비선점 SJF
- **선점형(Preemptive)**
  - 타임 슬라이스 만료, 우선순위 변경 시 CPU 강제 회수
  - 응답성 우수, 문맥 교환 비용 증가
  - 예: Round Robin, SRTF, MLFQ

현대 운영체제는 대부분 **선점형 스케줄링**을 사용한다.

---

### 주요 스케줄링 알고리즘

1. FCFS (First Come First Served)

   - 먼저 도착한 프로세스를 먼저 실행
   - 가장 단순한 스케줄링 방식

   FCFS는 구현이 매우 간단하지만 **Convoy Effect** 문제가 발생한다.

   하나의 긴 작업이 앞에 오면, 뒤의 짧은 작업들이 모두 대기하게 되어 전체 응답성이 급격히 나빠진다.

   - Convoy Effect ?
     Convoy = 호송대
     > 느린 트럭 하나 때문에 고속도로에 차들이 줄지어 막히는 상황과 비슷
     **발생 과정**
     1. 실행 시간이 긴 프로세스가 먼저 CPU를 잡는다
     2. CPU를 끝날 때까지 독점한다
     3. 뒤에 온 짧은 프로세스들은 전부 대기한다
     4. 전체 평균 대기 시간이 증가한다
     ⇒ **긴 작업 하나가 시스템 전체를 느리게 만드는 현상**

1. SJF / SRTF (Shortest Job First / Shortest Remaining Time First)

   - 실행 시간이 가장 짧은 프로세스를 우선 실행
   - 평균 대기 시간 최소화

   이론적으로 가장 효율적인 알고리즘이지만 **실행 시간을 정확히 예측하기 어렵다**는 치명적인 문제가 있다.

   또한 실행 시간이 긴 프로세스는 계속 밀려나는 **기아 상태(Starvation)** 가 발생할 수 있다.

1. Round Robin (RR)

   - 모든 프로세스에 동일한 타임 슬라이스를 할당
   - 타임 슬라이스 만료 시 Ready Queue 뒤로 이동

   Round Robin은 **대화형 시스템에 매우 적합**하다.

   하지만 성능은 타임 슬라이스 크기에 크게 의존한다.

   - 너무 크면 → FCFS처럼 동작
   - 너무 작으면 → 컨텍스트 스위칭 오버헤드 증가

1. MLFQ (Multi-Level Feedback Queue)

   - 여러 개의 우선순위 큐를 사용
   - CPU를 오래 쓰는 프로세스는 점점 낮은 우선순위로 이동
   - I/O 중심, 짧은 작업은 높은 우선순위 유지

   MLFQ는

   - 응답성
   - 공정성
   - 처리량

   을 균형 있게 만족시키려는 알고리즘이다.

   실행 시간 예측 없이도 동작하며, **기아 상태를 완화하기 위해 에이징(Aging) 기법**을 적용할 수 있다.

   이 때문에 실제 운영체제에서 가장 널리 사용된다.

1. 기아 상태(Starvation)와 에이징(Aging)

   기아 상태란 **특정 프로세스가 CPU를 할당받지 못하고 무한 대기하는 현상**이다.

   주로 다음 상황에서 발생한다.

   - 우선순위 기반 스케줄링
   - SJF / SRTF 계열 알고리즘

   이를 해결하기 위한 대표적인 방법이 **에이징(Aging)** 이다.

   에이징은 대기 시간이 길어질수록 프로세스의 우선순위를 점진적으로 높여

   결국 CPU를 할당받도록 보장하는 기법이다.

---

### 프로세스 간 상호작용 (IPC)

- 프로세스는 기본적으로 독립적이다
- 협력이 필요하다
- IPC는 동기화 문제를 동반한다

프로세스는 독립적이기 때문에 서로 직접 메모리를 공유하지 않는다.

하지만 현실의 프로그램은 서로 데이터를 주고받아야 한다.

이를 위해 운영체제는 **IPC(Inter-Process Communication)** 메커니즘을 제공한다.

대표적으로 Shared Memory와 Message Passing 방식이 있으며,

- **Shared Memory**
  동일한 메모리 영역을 공유
  매우 빠르지만 동기화 문제 발생
- **Message Passing**
  메시지를 통해 데이터 교환
  Pipe, Message Queue, Socket 등이 포함
  안전하지만 상대적으로 느림

---

### 동기화와 교착 상태

- 공유 자원은 위험하다
- 잘못하면 시스템이 멈춘다

여러 프로세스가 동시에 공유 자원에 접근하면 **경쟁 상태(Race Condition)** 가 발생할 수 있다.

이를 해결하기 위해 임계 구역 개념이 등장했고, Mutex, Semaphore 같은 동기화 도구가 사용된다.

- **Mutex**
  하나의 프로세스만 자원 사용 가능
  소유 개념 존재
- **Semaphore**
  정수 값 기반 자원 관리
  여러 개의 자원 제어 가능

하지만 자원을 잘못 설계하면 모든 프로세스가 서로를 기다리는 **교착 상태(Deadlock)** 가 발생할 수 있다.

Deadlock은 다음 네 조건이 동시에 만족될 때 발생한다.

- 상호 배제
- 점유 대기
- 비선점
- 순환 대기

이를 해결하기 위해

예방, 회피(은행원 알고리즘), 탐지 및 회복 기법이 존재한다.

- **예방(Prevention)**
  Deadlock 조건 자체를 구조적으로 제거
- **회피(Avoidance)**
  은행원 알고리즘처럼 항상 안전 상태를 유지하도록 자원 할당
- **탐지 및 회복(Detection & Recovery)**
  Deadlock 발생을 허용하고 사후 처리

---

### 교착 상태 회피: 은행원 알고리즘

- 교착 상태를 **사전에 회피**하는 방법이다.
- 자원 요청 시 **안전 상태 유지 여부**를 검사한다.
- 이론적으로 완벽하지만 현실에서는 거의 쓰이지 않는다.

교착 상태 회피(Avoidance)는 자원이 남아 있어도 **Deadlock 가능성이 있으면 할당하지 않는 전략**이다.

이를 판단하는 대표적인 기법이 **은행원 알고리즘(Banker’s Algorithm)** 이다.

1. 핵심 개념

   은행원 알고리즘은 모든 프로세스가 **정상 종료 가능한 상태(Safe State)** 를

   항상 유지하도록 자원을 할당한다.

   이를 위해 운영체제는 다음 정보를 알고 있어야 한다.

   - **Max**: 프로세스의 최대 자원 요구량
   - **Allocation**: 현재 할당된 자원
   - **Need = Max − Allocation**
   - **Available**: 가용 자원

2. 안전 상태(Safe State)

   안전 상태란

   > 어떤 실행 순서를 택해도 모든 프로세스가 자원을 반납하고 종료할 수 있는 상태

   를 의미한다.

   운영체제는 자원 요청이 들어오면

   1. 요청을 **가상으로 할당**
   2. 안전 상태 여부 검사
   3. 안전하면 할당, 아니면 거절 또는 대기

   불안전 상태는 Deadlock은 아니지만, Deadlock으로 이어질 가능성이 있어 회피 대상이다.

3. 특징과 한계
   - Deadlock을 **사전에 완벽히 차단**
   - 최대 자원 요구량을 **미리 알아야 함**
   - 계산 비용이 커 **현대 OS에서는 거의 사용되지 않음**

---

### 제미나이가 만들어 준 운영체제 프로세스 질문

**Q1. 프로세스와 스레드의 차이는 무엇인가요?**

> 프로세스는 **독립된 주소 공간(Code, Data, Heap, Stack)**을 가지는 자원 할당의 단위이고, 스레드는 **프로세스 내부에서 실행 흐름만 분리한 실행의 단위**입니다.
>
> 프로세스 간에는 메모리를 공유하지 않아 안정성이 높지만 생성·전환 비용이 큽니다.
>
> 반면 스레드는 메모리를 공유해 효율적이지만 하나의 스레드 오류가 전체 프로세스에 영향을 줄 수 있습니다.

**프로세스(Process)**

- 실행 중인 프로그램, **독립적 주소 공간(Code/Data/Heap/Stack)** 보유
- CPU와 메모리 등 자원을 할당받는 단위
- 한 프로세스 오류가 다른 프로세스에 영향 없음

**스레드(Thread)**

- 프로세스 내 **실행 흐름 단위**, 코드/데이터/힙은 공유
- 독립적인 Stack과 레지스터 사용
- 효율적이고 가벼움, 하지만 한 스레드 오류 시 프로세스 전체 영향 가능

**Q2. 멀티 프로세스와 멀티 스레드의 장단점과, 어떤 경우에 무엇을 사용하는 게 좋을지 설명해주세요.**

> 멀티 프로세스는 프로세스 간 주소 공간이 분리되어 **안정성이 높고 장애 격리가 가능**하지만, IPC 비용과 컨텍스트 스위칭 비용이 큽니다.
>
> 멀티 스레드는 메모리를 공유해 **성능과 응답성이 뛰어나지만**, 동기화 문제와 오류 전파 위험이 있습니다.
>
> 그래서 크롬처럼 안정성이 중요한 경우 멀티 프로세스를, 서버 내부 병렬 처리에는 멀티 스레드를 사용합니다.

**멀티 프로세스**

- 여러 프로세스를 동시에 실행
- 장점: 안정성 높음, 프로세스 격리
- 단점: 통신(IPC) 복잡, 문맥 교환 비용 높음
- ex. 구글 크롬 브라우저, 서버 애플리케이션

**멀티 스레드**

- 한 프로세스 내 여러 스레드를 동시에 실행
- 장점: 효율적, 빠른 실행, 자원 공유
- 단점: 동기화 필요, 한 스레드 오류가 전체 영향 가능
- ex. 백그라운드 계산, 병렬 처리, UI와 작업 분리

**Q3. 컨텍스트 스위칭(Context Switching)이 무엇이며, 이때 발생하는 오버헤드(Overhead)에는 구체적으로 어떤 것들이 있나요?**

> 컨텍스트 스위칭은 **현재 실행 중인 프로세스의 문맥을 PCB에 저장하고 다른 프로세스의 문맥을 복원하는 과정**입니다.
>
> 이때 레지스터 저장·복원, PCB 접근 비용이 발생합니다.
>
> 또한 CPU 캐시가 무효화되는 **Cache Pollution**과 **TLB Flush**로 인해 성능 저하가 발생할 수 있습니다.

**Q4. PCB(Process Control Block)는 무엇이며, 왜 커널 영역에서 관리되나요?**

> PCB는 프로세스의 상태, 레지스터, 메모리 정보 등을 담고 있는 **프로세스 관리용 커널 자료구조**입니다.
>
> 컨텍스트 스위칭 시 실행 대상을 결정하는 기준이 됩니다.
>
> 사용자 영역에서 접근 가능하다면 프로세스 상태 조작으로 시스템 안정성이 붕괴될 수 있어, 보안과 안정성을 위해 반드시 **커널 영역에서만 관리**됩니다.

**Q5. `fork()`와 `exec()`의 차이점은 무엇인가요?**

> fork()는 현재 프로세스를 복제해 **새로운 프로세스(PID가 다른 자식)** 를 생성합니다.
>
> 이때 Copy-on-Write로 메모리 복사 비용을 최소화합니다.
>
> exec()는 기존 프로세스를 유지한 채 **메모리 공간을 새로운 프로그램으로 덮어씌워 실행**합니다.
>
> 즉, fork()는 생성이고 exec()는 교체입니다.

**Q6. CPU 스케줄링에서 '기아 상태(Starvation)'란 무엇이며, 이를 해결하기 위한 방법은 무엇인가요?**

> 기아 상태는 **우선순위가 낮은 프로세스가 CPU를 계속 할당받지 못하고 무한 대기하는 현상**입니다.
>
> 주로 우선순위 기반 스케줄링에서 발생합니다.
>
> 이를 해결하기 위해 **에이징(Aging)** 기법을 사용해, 대기 시간이 길어질수록 우선순위를 점진적으로 높입니다.

**Q7. IPC(프로세스 간 통신) 기법 중 공유 메모리(Shared Memory)와 메시지 전달(Message Passing) 모델의 차이를 설명해주세요.**

> 공유 메모리는 여러 프로세스가 동일한 메모리 영역을 사용해 **속도가 매우 빠르지만**, 동기화 문제를 반드시 직접 해결해야 합니다.
>
> 메시지 전달 방식은 커널을 통해 데이터를 주고받아 **안전하고 구현이 단순**하지만, 시스템 콜과 복사 비용으로 오버헤드가 큽니다.

**Q8. 뮤텍스(Mutex)와 세마포어(Semaphore)의 차이점은 무엇인가요?**

> 뮤텍스는 **하나의 프로세스 또는 스레드만 접근 가능한 Lock**이며, Lock을 획득한 주체만 해제할 수 있는 **소유 개념**이 있습니다.
>
> 세마포어는 **정수 값을 이용해 여러 개의 접근을 허용**할 수 있고, 소유 개념 없이 누구나 signal로 해제할 수 있습니다.

**Q9. 교착 상태(Deadlock)가 발생하기 위한 4가지 필요충분조건은 무엇인가요?**

> 교착 상태는 **상호 배제, 점유 대기, 비선점, 순환 대기**가 동시에 만족될 때 발생합니다.
>
> 이 네 조건 중 하나라도 깨지면 Deadlock은 발생하지 않습니다.
>
> 그래서 예방, 회피, 탐지 기법은 이 조건을 기준으로 설계됩니다.

**Q10. 임계 구역(Critical Section) 문제를 해결하기 위해 만족해야 할 3가지 조건은 무엇인가요?**

> 임계 구역에는 한 번에 하나만 접근해야 하는 **상호 배제**가 보장되어야 합니다.
>
> 또한 임계 구역이 비어 있다면 **진입이 지연되지 않아야 하고**, 어떤 프로세스도 **무한 대기하지 않도록 한정 대기**가 보장되어야 합니다.

**임계 구역(Critical Section)**

- 여러 프로세스(또는 스레드)가 공유 자원에 접근할 때, **동시에 접근하면 안 되는 코드 영역**
- **목적:** 데이터의 **경쟁 상태(Race Condition)** 방지
- ex. 은행 계좌 잔액 업데이트, 공유 메모리 접근, 파일 쓰기

즉, **공유 자원을 안전하게 다루기 위해 한 번에 하나만 들어갈 수 있는 영역**이 바로 임계 구역이다.
